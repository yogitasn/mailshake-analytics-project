{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc24939d-e715-4700-89a0-13cb4a89183e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Single-date mode enabled: 2025-12-25\n",
      "üìÇ activity_sent | client_1 | 2025-12-25\n",
      "‚ö†Ô∏è Adding missing column: recipient_fields_status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Written 25 records\n",
      "üìÇ activity_sent | client_2 | 2025-12-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Written 25 records\n",
      "üìÇ activity_sent | client_3 | 2025-12-25\n",
      "‚ö†Ô∏è Adding missing column: recipient_fields_status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Written 25 records\n",
      "üìÇ created_leads | client_1 | 2025-12-25\n",
      "‚ö†Ô∏è Adding missing column: recipient_fields_first\n",
      "‚ö†Ô∏è Adding missing column: recipient_fields_status\n",
      "‚ö†Ô∏è Adding missing column: assignedto_object\n",
      "‚ö†Ô∏è Adding missing column: assignedto_id\n",
      "‚ö†Ô∏è Adding missing column: assignedto_emailaddress\n",
      "‚ö†Ô∏è Adding missing column: assignedto_fullname\n",
      "‚ö†Ô∏è Adding missing column: assignedto_first\n",
      "‚ö†Ô∏è Adding missing column: assignedto_last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Written 100 records\n",
      "üìÇ created_leads | client_2 | 2025-12-25\n",
      "‚ö†Ô∏è Adding missing column: recipient_fields_first\n",
      "‚ö†Ô∏è Adding missing column: assignedto_object\n",
      "‚ö†Ô∏è Adding missing column: assignedto_id\n",
      "‚ö†Ô∏è Adding missing column: assignedto_emailaddress\n",
      "‚ö†Ô∏è Adding missing column: assignedto_fullname\n",
      "‚ö†Ô∏è Adding missing column: assignedto_first\n",
      "‚ö†Ô∏è Adding missing column: assignedto_last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Written 43 records\n",
      "üìÇ created_leads | client_3 | 2025-12-25\n",
      "‚ö†Ô∏è Adding missing column: recipient_fields_status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Written 16 records\n",
      "üéâ All datasets processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, max, lit, current_timestamp, current_date, explode_outer\n",
    ")\n",
    "from pyspark.sql.types import NullType, StringType, StructType, ArrayType\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ============================================================================\n",
    "# SPARK SESSION\n",
    "# ============================================================================\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"MailshakeCampaignCurations\")\n",
    "    .config(\n",
    "        \"spark.driver.extraClassPath\",\n",
    "        \"/opt/spark/jars/hadoop-aws-3.3.4.jar:/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\"\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.executor.extraClassPath\",\n",
    "        \"/opt/spark/jars/hadoop-aws-3.3.4.jar:/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "\n",
    "# ============================================================================\n",
    "# S3 CONFIG\n",
    "# ============================================================================\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.access.key\", os.getenv(\"AWS_ACCESS_KEY_ID\"))\n",
    "hadoop_conf.set(\"fs.s3a.secret.key\", os.getenv(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "hadoop_conf.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIG\n",
    "# ============================================================================\n",
    "RAW_PATH = \"s3a://mailshake-analytics/raw\"\n",
    "CURATED_PATH = \"s3a://mailshake-analytics/curated\"\n",
    "CLIENT_IDS = [\"client_1\", \"client_2\", \"client_3\"]\n",
    "\n",
    "SINGLE_DATE = \"2025-12-25\"   # set None for incremental\n",
    "BOOTSTRAP_DATE = \"2025-12-20\"\n",
    "\n",
    "# ============================================================================\n",
    "# HELPERS\n",
    "# ============================================================================\n",
    "\n",
    "def sanitize_column_names(df):\n",
    "    \"\"\"Replace invalid characters and dots in column names with underscores\"\"\"\n",
    "    for col_name in df.columns:\n",
    "        clean = re.sub(r'[^a-zA-Z0-9_]', '_', col_name)\n",
    "        clean = re.sub(r'_+', '_', clean).lower()\n",
    "        if clean != col_name:\n",
    "            df = df.withColumnRenamed(col_name, clean)\n",
    "    return df\n",
    "\n",
    "def fix_void_columns(df):\n",
    "    \"\"\"Cast NullType columns so Parquet can write.\"\"\"\n",
    "    for field in df.schema.fields:\n",
    "        if isinstance(field.dataType, NullType):\n",
    "            df = df.withColumn(field.name, col(field.name).cast(StringType()))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def ensure_columns_and_reorder(df: DataFrame, column_order: list, column_types: dict = None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure all columns exist (with specified data types if provided) and reorder DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): input DataFrame\n",
    "        column_order (list): list of columns in the desired order\n",
    "        column_types (dict, optional): dictionary of {column_name: DataType} for missing columns\n",
    "    Returns:\n",
    "        DataFrame with all columns present and reordered\n",
    "    \"\"\"\n",
    "    column_types = column_types or {}\n",
    "\n",
    "    for col_name in column_order:\n",
    "        if col_name not in df.columns:\n",
    "            dtype = column_types.get(col_name)\n",
    "            if dtype:\n",
    "                df = df.withColumn(col_name, lit(None).cast(dtype))\n",
    "            else:\n",
    "                df = df.withColumn(col_name, lit(None))\n",
    "            print(f\"‚ö†Ô∏è Adding missing column: {col_name}\")\n",
    "\n",
    "    # Select columns in the desired order\n",
    "    df = df.select([col(c) for c in column_order])\n",
    "    return df\n",
    "\n",
    "\n",
    "def flatten_struct_columns(df):\n",
    "    \"\"\"Flatten all StructType columns and explode arrays of structs.\"\"\"\n",
    "    while True:\n",
    "        struct_cols = [\n",
    "            field.name\n",
    "            for field in df.schema.fields\n",
    "            if isinstance(field.dataType, StructType)\n",
    "        ]\n",
    "\n",
    "        if not struct_cols:\n",
    "            break\n",
    "\n",
    "        for col_name in struct_cols:\n",
    "            for nested in df.schema[col_name].dataType.fields:\n",
    "                df = df.withColumn(\n",
    "                    f\"{col_name}_{nested.name}\",\n",
    "                    col(f\"{col_name}.{nested.name}\")\n",
    "                )\n",
    "            df = df.drop(col_name)\n",
    "\n",
    "    # Explode array<struct> columns\n",
    "    array_struct_cols = [\n",
    "        field.name\n",
    "        for field in df.schema.fields\n",
    "        if isinstance(field.dataType, ArrayType) and isinstance(field.dataType.elementType, StructType)\n",
    "    ]\n",
    "\n",
    "    for col_name in array_struct_cols:\n",
    "        df = df.withColumn(col_name, explode_outer(col(col_name)))\n",
    "        for nested in df.schema[col_name].dataType.fields:\n",
    "            df = df.withColumn(f\"{col_name}_{nested.name}\", col(f\"{col_name}.{nested.name}\"))\n",
    "        df = df.drop(col_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_dates_to_process(curated_path, client_ids, single_date=None, bootstrap_date=\"2025-12-20\"):\n",
    "    if single_date:\n",
    "        print(f\"üìÖ Single-date mode enabled: {single_date}\")\n",
    "        return {c: [single_date] for c in client_ids}\n",
    "\n",
    "    dates = {}\n",
    "    try:\n",
    "        existing = spark.read.parquet(curated_path)\n",
    "        last_dates = (\n",
    "            existing.groupBy(\"client_id\")\n",
    "            .agg(max(\"source_date\").alias(\"last_date\"))\n",
    "            .collect()\n",
    "        )\n",
    "        last_map = {r[\"client_id\"]: r[\"last_date\"] for r in last_dates}\n",
    "    except Exception:\n",
    "        last_map = {}\n",
    "\n",
    "    today = datetime.today()\n",
    "    for client in client_ids:\n",
    "        start = (\n",
    "            datetime.strptime(str(last_map[client]), \"%Y-%m-%d\") + timedelta(days=1)\n",
    "            if client in last_map\n",
    "            else datetime.strptime(bootstrap_date, \"%Y-%m-%d\")\n",
    "        )\n",
    "        dates[client] = [\n",
    "            (start + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
    "            for i in range((today - start).days + 1)\n",
    "        ]\n",
    "    return dates\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET PROCESSOR\n",
    "# ============================================================================\n",
    "def process_dataset(\n",
    "    raw_base_path,\n",
    "    curated_base_path,\n",
    "    client_ids,\n",
    "    dataset_name,\n",
    "    unique_keys,\n",
    "    explode_col=None,\n",
    "    dates_per_client=None,\n",
    "    desired_columns =None,\n",
    "    column_types=None\n",
    "):\n",
    "    entity_path = f\"{curated_base_path}/entity={dataset_name}\"\n",
    "\n",
    "    for client_id in client_ids:\n",
    "        for process_date in dates_per_client.get(client_id, []):\n",
    "            input_path = (\n",
    "                f\"{raw_base_path}/client_id={client_id}/entity={dataset_name}/date={process_date}/\"\n",
    "            )\n",
    "            try:\n",
    "                print(f\"üìÇ {dataset_name} | {client_id} | {process_date}\")\n",
    "\n",
    "                df = spark.read.parquet(input_path)\n",
    "\n",
    "                df = flatten_struct_columns(df)   # flatten structs and arrays first\n",
    "\n",
    "                if explode_col:\n",
    "                    explode_col = explode_col.replace(\".\", \"_\")\n",
    "                    if explode_col in df.columns:\n",
    "                        df = df.withColumn(explode_col, explode_outer(col(explode_col)))\n",
    "\n",
    "                # Sanitize column names\n",
    "                df = sanitize_column_names(df)\n",
    "\n",
    "                # Ensure all columns exist and reorder\n",
    "                df = ensure_columns_and_reorder(df, desired_columns,column_types)\n",
    "\n",
    "                # Add metadata\n",
    "                df = (\n",
    "                    df.withColumn(\"client_id\", lit(client_id))\n",
    "                      .withColumn(\"source_date\", lit(process_date))\n",
    "                      .withColumn(\"client_id_col\", lit(client_id))\n",
    "                      .withColumn(\"source_date_col\", lit(process_date))\n",
    "                      .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "                      .withColumn(\"processing_date\", current_date())\n",
    "                      .withColumn(\"load_type\", lit(\"single_date\" if SINGLE_DATE else \"incremental\"))\n",
    "                )\n",
    "\n",
    "               # # Add missing columns\n",
    "               # if required_columns:\n",
    "                #    df = add_explicit_missing_columns(df, required_columns)\n",
    "\n",
    "                # Deduplicate\n",
    "                safe_keys = [k.replace(\".\", \"_\") for k in unique_keys]\n",
    "                df = df.dropDuplicates(safe_keys + [\"client_id\", \"source_date\"])\n",
    "\n",
    "                df = fix_void_columns(df)\n",
    "\n",
    "                # Write\n",
    "                df.write.mode(\"overwrite\").partitionBy(\"client_id\", \"source_date\").parquet(entity_path)\n",
    "                print(f\"‚úÖ Written {df.count()} records\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Skipped {dataset_name} | {client_id} | {process_date}: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RUN\n",
    "# ============================================================================\n",
    "dates_per_client = get_dates_to_process(CURATED_PATH, CLIENT_IDS, single_date=SINGLE_DATE, bootstrap_date=BOOTSTRAP_DATE)\n",
    "\n",
    "# -------------------- activity_open --------------------\n",
    "process_dataset(\n",
    "    RAW_PATH, CURATED_PATH, CLIENT_IDS,\n",
    "    \"activity_open\",\n",
    "    unique_keys=[\"id\", \"recipient.id\", \"campaign.id\"],\n",
    "    dates_per_client=dates_per_client,\n",
    "    desired_columns = [\n",
    "            \"object\", \"id\", \"actiondate\", \"isduplicate\", \"recipient_object\",\n",
    "            \"recipient_id\", \"recipient_emailaddress\", \"recipient_fullname\",\n",
    "            \"recipient_created\", \"recipient_ispaused\", \"recipient_contactid\",\n",
    "            \"recipient_first\", \"recipient_last\", \"recipient_fields_link\",\n",
    "            \"recipient_fields_status\", \"recipient_fields_first\",\n",
    "            \"recipient_fields_position\", \"recipient_fields_date_applied\",\n",
    "            \"recipient_fields_account\", \"recipient_fields_phonenumber\",\n",
    "            \"recipient_fields_facebookurl\", \"recipient_fields_instagramid\",\n",
    "            \"recipient_fields_linkedinurl\", \"recipient_fields_twitterid\",\n",
    "            \"campaign_object\", \"campaign_id\", \"campaign_title\", \"campaign_wizardstatus\",\n",
    "            \"parent_object\", \"parent_id\", \"parent_type\", \"parent_message_object\",\n",
    "            \"parent_message_id\", \"parent_message_type\", \"parent_message_subject\",\n",
    "            \"parent_message_replytoid\"\n",
    "        ],\n",
    "            # Optional: specify data types for missing columns\n",
    "        column_types = {\n",
    "            \"recipient_fields_status\": StringType(),\n",
    "            \"recipient_fields_first\": StringType()\n",
    "        }\n",
    ")\n",
    "\n",
    "# -------------------- activity_reply --------------------\n",
    "process_dataset(\n",
    "    RAW_PATH, CURATED_PATH, CLIENT_IDS,\n",
    "    \"activity_reply\",\n",
    "    unique_keys=[\"id\", \"recipient.id\", \"campaign.id\"],\n",
    "    dates_per_client=dates_per_client,\n",
    "    desired_columns = [\n",
    "            \"object\", \"id\", \"actiondate\",\n",
    "            \"type\", \"subject\", \"externalid\",\n",
    "            \"externalrawmessageid\", \"externalconversationid\", \"rawbody\",\n",
    "            \"body\", \"plaintextbody\", \"recipient_object\",\n",
    "            \"recipient_id\", \"recipient_emailaddress\", \"recipient_fullname\",\n",
    "            \"recipient_created\", \"recipient_ispaused\", \"recipient_contactid\",\n",
    "            \"recipient_first\", \"recipient_last\", \"recipient_fields_link\",\n",
    "            \"recipient_fields_status\",  \"recipient_fields_first\", \"recipient_fields_position\", \"recipient_fields_date_applied\",\n",
    "            \"recipient_fields_account\", \"recipient_fields_phonenumber\", \"recipient_fields_facebookurl\",\n",
    "            \"recipient_fields_instagramid\", \"recipient_fields_linkedinurl\", \"recipient_fields_twitterid\",\n",
    "            \"campaign_object\", \"campaign_id\", \"campaign_title\",\n",
    "            \"campaign_wizardstatus\", \"parent_object\", \"parent_id\",\n",
    "            \"parent_type\", \"parent_message_object\", \"parent_message_id\",\n",
    "            \"parent_message_type\", \"parent_message_subject\", \"parent_message_replytoid\",\n",
    "            \"from_object\", \"from_address\", \"from_fullname\",\n",
    "            \"from_first\", \"from_last\"\n",
    "            ],\n",
    "    column_types ={\"recipient_fields_status\": StringType(),\n",
    "                     \"recipient_fields_first\": StringType()}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- activity_sent --------------------\n",
    "process_dataset(\n",
    "    RAW_PATH, CURATED_PATH, CLIENT_IDS,\n",
    "    \"activity_sent\",\n",
    "    unique_keys=[\"id\", \"recipient.id\", \"campaign.id\"],\n",
    "    explode_col=\"to\",\n",
    "    dates_per_client=dates_per_client,\n",
    "    desired_columns =\n",
    "                    # Core\n",
    "                    [\"object\", \"id\", \"actiondate\",\n",
    "                    \"type\", \"excludebody\",\n",
    "                    # To (exploded)\n",
    "                    \"to_address\", \"to_first\", \"to_fullname\",\n",
    "                    \"to_last\", \"to_object\",\n",
    "                    # Message content\n",
    "                    \"subject\", \"externalid\", \"externalrawmessageid\",\n",
    "                    \"externalconversationid\", \"rawbody\", \"body\",\n",
    "                    \"plaintextbody\",\n",
    "                    # Recipient\n",
    "                    \"recipient_object\", \"recipient_id\", \"recipient_emailaddress\",\n",
    "                    \"recipient_fullname\", \"recipient_created\", \"recipient_ispaused\",\n",
    "                    \"recipient_first\", \"recipient_last\",\n",
    "                    # Recipient fields\n",
    "                    \"recipient_fields_account\", \"recipient_fields_phonenumber\",\n",
    "                    \"recipient_fields_facebookurl\", \"recipient_fields_instagramid\",\n",
    "                    \"recipient_fields_linkedinurl\", \"recipient_fields_twitterid\",\n",
    "                    \"recipient_fields_link\", \"recipient_fields_position\",\n",
    "                    \"recipient_fields_date_applied\", \"recipient_fields_status\",\n",
    "                    # Campaign\n",
    "                    \"campaign_object\", \"campaign_id\",\n",
    "                    \"campaign_title\", \"campaign_wizardstatus\",\n",
    "                    # Message (parent)\n",
    "                    \"message_object\", \"message_id\", \"message_type\",\n",
    "                    \"message_subject\", \"message_replytoid\",\n",
    "                    # From\n",
    "                    \"from_object\", \"from_address\", \"from_fullname\",\n",
    "                    \"from_first\", \"from_last\"],\n",
    "      column_types={\"recipient_fields_status\": StringType()}\n",
    ")\n",
    "\n",
    "# -------------------- created_leads --------------------\n",
    "process_dataset(\n",
    "    RAW_PATH, CURATED_PATH, CLIENT_IDS,\n",
    "    \"created_leads\",\n",
    "    unique_keys=[\"id\", \"recipient.id\", \"campaign.id\"],\n",
    "    dates_per_client=dates_per_client,\n",
    "    desired_columns = [\n",
    "    \"object\", \"id\", \"created\",\n",
    "    \"openeddate\", \"laststatuschangedate\", \"annotation\",\n",
    "    \"status\",\n",
    "\n",
    "    \"recipient_object\", \"recipient_id\", \"recipient_emailaddress\",\n",
    "    \"recipient_fullname\", \"recipient_created\", \"recipient_ispaused\",\n",
    "    \"recipient_contactid\", \"recipient_first\", \"recipient_last\",\n",
    "\n",
    "    \"recipient_fields_link\", \"recipient_fields_first\",\n",
    "    \"recipient_fields_status\", \"recipient_fields_position\",\n",
    "    \"recipient_fields_date_applied\", \"recipient_fields_account\",\n",
    "    \"recipient_fields_phonenumber\", \"recipient_fields_facebookurl\",\n",
    "    \"recipient_fields_instagramid\", \"recipient_fields_linkedinurl\",\n",
    "    \"recipient_fields_twitterid\",\n",
    "\n",
    "    \"campaign_object\", \"campaign_id\",\n",
    "    \"campaign_title\", \"campaign_wizardstatus\",\n",
    "\n",
    "    \"assignedto_object\", \"assignedto_id\",\n",
    "    \"assignedto_emailaddress\", \"assignedto_fullname\",\n",
    "    \"assignedto_first\", \"assignedto_last\"\n",
    "]       ,\n",
    "    column_types={  \"recipient_fields_status\": StringType(),\n",
    "                    \"recipient_fields_first\": StringType(),\n",
    "                    \"assignedto_object\": StringType(),\n",
    "                    \"assignedto_id\": DoubleType(),\n",
    "                    \"assignedto_emailaddress\": StringType(),\n",
    "                    \"assignedto_fullname\": StringType(),\n",
    "                    \"assignedto_first\": StringType(),\n",
    "                    \"assignedto_last\": StringType()\n",
    "}\n",
    ")\n",
    "\n",
    "spark.stop()\n",
    "print(\"üéâ All datasets processed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
