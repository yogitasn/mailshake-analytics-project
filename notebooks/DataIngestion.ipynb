{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ff4bfb-6012-4c21-9ad8-fa190135011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.4 MB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.20.3; python_version < \"3.10\"\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.3 MB 44 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: numpy, tzdata, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1285345f-ce9c-4e9f-8eb6-4161fcf849c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.37.38-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.38.0,>=1.37.38\n",
      "  Downloading botocore-1.37.38-py3-none-any.whl (13.5 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.5 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.12.0,>=0.11.0\n",
      "  Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4; python_version < \"3.10\"\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 144 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.38.0,>=1.37.38->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.38->boto3) (1.17.0)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed boto3-1.37.38 botocore-1.37.38 jmespath-1.0.1 s3transfer-0.11.5 urllib3-1.26.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea47a8d-3089-4987-80c3-c2153efb337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40.0 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from pyarrow) (1.24.4)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2015bb-f99c-4902-b765-91abf099f2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ STARTING Team 97170\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=False\n",
      "2026-01-18T22:38:35+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (21)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (27)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (33)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (19)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-23T22:10:16+0000\n",
      "‚û° activity_reply | first_run=False\n",
      "2026-01-16T21:47:32+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (1)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (2)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (2)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (1)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (1)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-23T02:33:39+0000\n",
      "‚û° activity_sent | first_run=False\n",
      "2026-01-16T22:56:57+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (25)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-23T22:48:05+0000\n",
      "‚û° activity_clicks | first_run=True\n",
      "‚ö†Ô∏è No new records for activity_clicks\n",
      "‚û° created_leads | first_run=False\n",
      "2026-01-15T16:42:52+0000\n",
      "üü¢ INCREMENTAL ‚Üí created_leads (1)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-21T14:36:23+0000\n",
      "‚úÖ Team 97170 COMPLETED\n",
      "\n",
      "üöÄ STARTING Team 112165\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=False\n",
      "2026-01-18T18:16:37+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (5)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (29)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (12)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (17)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (11)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (10)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-24T19:14:14+0000\n",
      "‚û° activity_reply | first_run=False\n",
      "2026-01-18T21:10:02+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (5)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (6)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (4)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (4)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (6)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-24T20:36:59+0000\n",
      "‚û° activity_sent | first_run=False\n",
      "2026-01-18T21:09:59+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (25)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-24T21:10:58+0000\n",
      "‚û° activity_clicks | first_run=False\n",
      "2026-01-18T20:24:01+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_clicks (1)\n",
      "üü¢ INCREMENTAL ‚Üí activity_clicks (5)\n",
      "üü¢ INCREMENTAL ‚Üí activity_clicks (6)\n",
      "üü¢ INCREMENTAL ‚Üí activity_clicks (2)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-22T16:24:24+0000\n",
      "‚û° created_leads | first_run=False\n",
      "2026-01-15T20:59:06+0000\n",
      "‚ö†Ô∏è No new records for created_leads after watermark 2026-01-15T20:59:06+0000\n",
      "‚úÖ Team 112165 COMPLETED\n",
      "\n",
      "üöÄ STARTING Team 106422\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=False\n",
      "2026-01-17T01:56:37+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (4)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (5)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-22T05:41:56+0000\n",
      "‚û° activity_reply | first_run=False\n",
      "2026-01-15T02:47:22+0000\n",
      "‚ö†Ô∏è No new records for activity_reply after watermark 2026-01-15T02:47:22+0000\n",
      "‚û° activity_sent | first_run=False\n",
      "2026-01-09T20:57:57+0000\n",
      "‚ö†Ô∏è No new records for activity_sent after watermark 2026-01-09T20:57:57+0000\n",
      "‚û° activity_clicks | first_run=False\n",
      "2025-05-27T18:38:42+0000\n",
      "‚ö†Ô∏è No new records for activity_clicks after watermark 2025-05-27T18:38:42+0000\n",
      "‚û° created_leads | first_run=False\n",
      "2026-01-15T02:51:25+0000\n",
      "‚ö†Ô∏è No new records for created_leads after watermark 2026-01-15T02:51:25+0000\n",
      "‚úÖ Team 106422 COMPLETED\n",
      "\n",
      "üèÅ JOB FINISHED\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Dict, List, Any\n",
    "import boto3\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# GLOBALS\n",
    "# ============================================================================\n",
    "BASE = \"https://api.mailshake.com/2017-04-01\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "BUCKET = \"mailshake-analytics\"\n",
    "RAW_PREFIX = \"raw\"\n",
    "WATERMARK_PREFIX = \"metadata/watermark\"\n",
    "TEAMS_KEY = \"config/teams_test.json\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "RUN_DATE = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "API_CALL_DELAY_FIRST_RUN = 3.0\n",
    "API_CALL_DELAY_INCREMENTAL = 1.0\n",
    "\n",
    "MAX_PAGES_FIRST_RUN = 100\n",
    "MAX_PAGES_INCREMENTAL = 3\n",
    "\n",
    "is_first_run_mode = False\n",
    "api_call_count = 0\n",
    "start_time = None\n",
    "\n",
    "# ============================================================================\n",
    "# TEAM CONFIG\n",
    "# ============================================================================\n",
    "def load_teams() -> Dict[str, Dict[str, str]]:\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=TEAMS_KEY)\n",
    "    return json.loads(obj[\"Body\"].read().decode(\"utf-8\")).get(\"teams\", {})\n",
    "\n",
    "# ============================================================================\n",
    "# SAFE POST\n",
    "# ============================================================================\n",
    "def safe_post(url: str, payload: Dict[str, Any], auth: HTTPBasicAuth) -> requests.Response:\n",
    "    global api_call_count, start_time\n",
    "\n",
    "    if start_time is None:\n",
    "        start_time = time.time()\n",
    "\n",
    "    delay = API_CALL_DELAY_FIRST_RUN if is_first_run_mode else API_CALL_DELAY_INCREMENTAL\n",
    "    time.sleep(delay)\n",
    "\n",
    "    api_call_count += 1\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = api_call_count / (elapsed / 60) if elapsed > 0 else 0\n",
    "\n",
    "    resp = requests.post(url, json=payload, headers=HEADERS, auth=auth, timeout=30)\n",
    "\n",
    "    if resp.status_code == 429:\n",
    "        endpoint = url.split(\"/\")[-1]\n",
    "        mode = \"FIRST RUN\" if is_first_run_mode else \"INCREMENTAL\"\n",
    "        print(\"\\nüö´ RATE LIMIT HIT\")\n",
    "        print(f\"Endpoint: {endpoint}\")\n",
    "        print(f\"Mode: {mode}\")\n",
    "        print(f\"Rate: {rate:.1f} calls/min\")\n",
    "        raise SystemExit(1)\n",
    "\n",
    "    resp.raise_for_status()\n",
    "    return resp\n",
    "\n",
    "# ============================================================================\n",
    "# WATERMARK HELPERS\n",
    "# ============================================================================\n",
    "def read_watermarks(team_id: str) -> dict:\n",
    "    key = f\"{WATERMARK_PREFIX}/watermark_{team_id}.json\"\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        return json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "    except s3.exceptions.NoSuchKey:\n",
    "        return {}\n",
    "\n",
    "def update_watermarks(team_id: str, new_data: dict):\n",
    "    key = f\"{WATERMARK_PREFIX}/watermark_{team_id}.json\"\n",
    "    current = read_watermarks(team_id)\n",
    "    current.update(new_data)\n",
    "    s3.put_object(Bucket=BUCKET, Key=key, Body=json.dumps(current, indent=2).encode(\"utf-8\"))\n",
    "\n",
    "def get_watermark(team_id: str, entity: str) -> str:\n",
    "    return read_watermarks(team_id).get(entity, \"1970-01-01T00:00:00Z\")\n",
    "\n",
    "def normalize_iso(ts: str) -> str:\n",
    "    if not ts:\n",
    "        return ts\n",
    "    if ts.endswith(\"Z\"):\n",
    "        return ts.replace(\"Z\", \"+00:00\")\n",
    "    if len(ts) >= 5:\n",
    "        tz = ts[-5:]\n",
    "        if tz[0] in \"+-\" and tz[1:].isdigit() and \":\" not in tz:\n",
    "            return ts[:-5] + tz[:3] + \":\" + tz[3:]\n",
    "    return ts\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE PARQUET\n",
    "# ============================================================================\n",
    "def save_snapshot_or_incremental(\n",
    "    data: list, team_id: str, entity: str, ts_col: str, first_run: bool\n",
    "):\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if ts_col in df.columns:\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col], errors=\"coerce\", utc=True)\n",
    "        df = df.dropna(subset=[ts_col])\n",
    "        if df.empty:\n",
    "            return None\n",
    "        df[ts_col] = df[ts_col].dt.strftime(\"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "    batch_ts = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "\n",
    "    # FULL\n",
    "    if entity in [\"campaign\", \"created_leads\"]:\n",
    "        file = f\"/tmp/{team_id}_{entity}_full.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/team_id={team_id}/entity={entity}/snapshot/{entity}.parquet\"\n",
    "        df.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"‚úì {entity}: {len(df)} records (FULL)\")\n",
    "        return df[ts_col].max() if ts_col in df.columns else batch_ts\n",
    "\n",
    "    # FIRST RUN SNAPSHOT\n",
    "    if first_run and entity.startswith(\"activity_\"):\n",
    "        file = f\"/tmp/{team_id}_{entity}_snapshot.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/team_id={team_id}/entity={entity}/snapshot/{entity}.parquet\"\n",
    "        df.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"‚úì {entity}: {len(df)} records (SNAPSHOT 20d)\")\n",
    "        return df[ts_col].max()\n",
    "\n",
    "    # INCREMENTAL\n",
    "    current_wm = get_watermark(team_id, entity)\n",
    "    if ts_col in df.columns:\n",
    "        df = df[df[ts_col] > current_wm]\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    df[\"event_date\"] = pd.to_datetime(df[ts_col], utc=True).dt.strftime(\"%Y-%m-%d\")\n",
    "    new_wm = df[ts_col].max()\n",
    "\n",
    "    total = 0\n",
    "    for d in df[\"event_date\"].unique():\n",
    "        part = df[df[\"event_date\"] == d].drop(columns=[\"event_date\"])\n",
    "        suffix = new_wm.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "        file = f\"/tmp/{team_id}_{entity}_{d}_{suffix}.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/team_id={team_id}/entity={entity}/event_date={d}/{entity}_{suffix}.parquet\"\n",
    "        part.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        total += len(part)\n",
    "\n",
    "    print(f\"‚úì {entity}: {total} records (INCREMENTAL)\")\n",
    "    return new_wm\n",
    "\n",
    "# ============================================================================\n",
    "# FETCH FUNCTIONS\n",
    "# ============================================================================\n",
    "def fetch_campaigns(team_id: str, auth: HTTPBasicAuth) -> List[Dict[str, Any]]:\n",
    "    resp = safe_post(f\"{BASE}/campaigns/list\", {\"teamID\": team_id}, auth)\n",
    "    return resp.json().get(\"results\", []) or []\n",
    "\n",
    "def fetch_activity_with_since(\n",
    "    team_id: str, api_name: str, since_ts: str, auth: HTTPBasicAuth, first_run: bool\n",
    ") -> List[Dict[str, Any]]:\n",
    "    payload = {\"teamID\": team_id, \"perPage\": 100}\n",
    "\n",
    "    if first_run:\n",
    "        cutoff = datetime.now(timezone.utc) - timedelta(days=20)\n",
    "        payload[\"since\"] = cutoff.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        max_pages = MAX_PAGES_FIRST_RUN\n",
    "    elif since_ts and since_ts != \"1970-01-01T00:00:00Z\":\n",
    "        since_dt = datetime.fromisoformat(normalize_iso(since_ts))\n",
    "        payload[\"since\"] = since_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        max_pages = MAX_PAGES_INCREMENTAL\n",
    "    else:\n",
    "        max_pages = MAX_PAGES_FIRST_RUN\n",
    "\n",
    "    results_all = []\n",
    "    page = 0\n",
    "\n",
    "    while True:\n",
    "        page += 1\n",
    "        if page > max_pages:\n",
    "            break\n",
    "\n",
    "        resp = safe_post(f\"{BASE}/activity/{api_name}\", payload, auth)\n",
    "        data = resp.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "        results_all.extend(results)\n",
    "        token = data.get(\"nextToken\")\n",
    "        if not token:\n",
    "            break\n",
    "\n",
    "        payload = {\"teamID\": team_id, \"nextToken\": token, \"perPage\": 100}\n",
    "        if \"since\" in payload:\n",
    "            payload[\"since\"] = payload.get(\"since\")\n",
    "\n",
    "    return results_all\n",
    "\n",
    "def fetch_sent_activity(\n",
    "    team_id: str, watermark: str, first_run: bool, auth: HTTPBasicAuth\n",
    ") -> List[Dict[str, Any]]:\n",
    "    payload = {\"teamID\": team_id, \"perPage\": 100}\n",
    "    cutoff = (\n",
    "        datetime.now(timezone.utc) - timedelta(days=20)\n",
    "        if first_run\n",
    "        else datetime.fromisoformat(normalize_iso(watermark))\n",
    "    )\n",
    "\n",
    "    results_all = []\n",
    "    page = 0\n",
    "\n",
    "    while True:\n",
    "        page += 1\n",
    "        if page > (MAX_PAGES_FIRST_RUN if first_run else MAX_PAGES_INCREMENTAL):\n",
    "            break\n",
    "\n",
    "        resp = safe_post(f\"{BASE}/activity/sent\", payload, auth)\n",
    "        data = resp.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "        stop = False\n",
    "        for r in results:\n",
    "            ts = r.get(\"actionDate\")\n",
    "            if not ts:\n",
    "                continue\n",
    "            try:\n",
    "                dt = datetime.fromisoformat(normalize_iso(ts))\n",
    "            except:\n",
    "                continue\n",
    "            if dt >= cutoff:\n",
    "                results_all.append(r)\n",
    "            else:\n",
    "                stop = True\n",
    "\n",
    "        if stop and not first_run:\n",
    "            break\n",
    "\n",
    "        token = data.get(\"nextToken\")\n",
    "        if not token:\n",
    "            break\n",
    "\n",
    "        payload = {\"teamID\": team_id, \"nextToken\": token, \"perPage\": 100}\n",
    "\n",
    "    return results_all\n",
    "\n",
    "# ============================================================================\n",
    "# RUN TEAM\n",
    "# ============================================================================\n",
    "def run_team(team: Dict[str, str]):\n",
    "    global is_first_run_mode\n",
    "\n",
    "    team_id, auth = team[\"team_id\"], HTTPBasicAuth(team[\"api_token\"], \"\")\n",
    "    print(f\"\\nüöÄ Team {team_id}\")\n",
    "\n",
    "    watermarks = read_watermarks(team_id)\n",
    "    is_first_run_mode = len(watermarks) == 0\n",
    "    print(\"üÜï FIRST RUN\" if is_first_run_mode else \"üîÑ INCREMENTAL RUN\")\n",
    "\n",
    "    campaigns = fetch_campaigns(team_id, auth)\n",
    "    if campaigns:\n",
    "        wm = save_snapshot_or_incremental(campaigns, team_id, \"campaign\", \"created\", True)\n",
    "        if wm:\n",
    "            update_watermarks(team_id, {\"campaign\": wm})\n",
    "\n",
    "    activity_config = {\n",
    "        \"activity_sent\": (\"sent\", \"actionDate\", False),\n",
    "        \"activity_open\": (\"opens\", \"actionDate\", True),\n",
    "        \"activity_reply\": (\"replies\", \"actionDate\", True),\n",
    "        \"activity_clicks\": (\"clicks\", \"actionDate\", True),\n",
    "        \"created_leads\": (\"created-leads\", \"created\", True),\n",
    "    }\n",
    "\n",
    "    watermarks = read_watermarks(team_id)\n",
    "\n",
    "    for entity, (api, ts_col, supports_since) in activity_config.items():\n",
    "        first_run = entity not in watermarks\n",
    "        watermark = watermarks.get(entity, \"1970-01-01T00:00:00Z\")\n",
    "\n",
    "        data = (\n",
    "            fetch_activity_with_since(team_id, api, watermark, auth, first_run)\n",
    "            if supports_since\n",
    "            else fetch_sent_activity(team_id, watermark, first_run, auth)\n",
    "        )\n",
    "\n",
    "        if not data:\n",
    "            continue\n",
    "\n",
    "        new_wm = save_snapshot_or_incremental(data, team_id, entity, ts_col, first_run)\n",
    "        if new_wm:\n",
    "            update_watermarks(team_id, {entity: new_wm})\n",
    "\n",
    "    print(f\"‚úÖ Team {team_id} completed\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    teams = load_teams()\n",
    "\n",
    "    print(f\"Teams to process: {len(teams)}\")\n",
    "\n",
    "    for _, team_cfg in teams.items():\n",
    "        try:\n",
    "            run_team(team_cfg)\n",
    "        except SystemExit:\n",
    "            print(\"üö´ RATE LIMIT ‚Äî STOPPING\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Team failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    if start_time:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nüèÅ JOB FINISHED\")\n",
    "        print(f\"Total API calls: {api_call_count}\")\n",
    "        print(f\"Total time: {elapsed/60:.1f} min\")\n",
    "        print(f\"Avg rate: {api_call_count/(elapsed/60):.1f} calls/min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d688d-40b8-42c4-8076-db8ef5ea83d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
