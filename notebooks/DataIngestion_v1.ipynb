{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ff4bfb-6012-4c21-9ad8-fa190135011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.4 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.20.3; python_version < \"3.10\"\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.3 MB 33 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2025.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: numpy, tzdata, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1285345f-ce9c-4e9f-8eb6-4161fcf849c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.37.38-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.12.0,>=0.11.0\n",
      "  Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.38\n",
      "  Downloading botocore-1.37.38-py3-none-any.whl (13.5 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.5 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.25.4; python_version < \"3.10\"\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 144 kB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.38.0,>=1.37.38->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.38->boto3) (1.17.0)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed boto3-1.37.38 botocore-1.37.38 jmespath-1.0.1 s3transfer-0.11.5 urllib3-1.26.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea47a8d-3089-4987-80c3-c2153efb337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40.0 MB 2.7 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from pyarrow) (1.24.4)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2015bb-f99c-4902-b765-91abf099f2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ STARTING Team 97170\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_open\n",
      "üîÅ Watermark updated ‚Üí 2026-01-18T22:38:35+0000\n",
      "‚û° activity_reply | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_reply\n",
      "üîÅ Watermark updated ‚Üí 2026-01-16T21:47:32+0000\n",
      "‚û° activity_sent | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_sent\n",
      "üîÅ Watermark updated ‚Üí 2026-01-16T22:56:57+0000\n",
      "‚û° activity_clicks | first_run=True\n",
      "‚ö†Ô∏è No new records for activity_clicks\n",
      "‚û° created_leads | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí created_leads\n",
      "üîÅ Watermark updated ‚Üí 2026-01-15T16:42:52+0000\n",
      "‚úÖ Team 97170 COMPLETED\n",
      "\n",
      "üöÄ STARTING Team 112165\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_open\n",
      "üîÅ Watermark updated ‚Üí 2026-01-18T18:16:37+0000\n",
      "‚û° activity_reply | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_reply\n",
      "üîÅ Watermark updated ‚Üí 2026-01-18T21:10:02+0000\n",
      "‚û° activity_sent | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_sent\n",
      "üîÅ Watermark updated ‚Üí 2026-01-18T21:09:59+0000\n",
      "‚û° activity_clicks | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_clicks\n",
      "üîÅ Watermark updated ‚Üí 2026-01-18T20:24:01+0000\n",
      "‚û° created_leads | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí created_leads\n",
      "üîÅ Watermark updated ‚Üí 2026-01-15T20:59:06+0000\n",
      "‚úÖ Team 112165 COMPLETED\n",
      "\n",
      "üöÄ STARTING Team 106422\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_open\n",
      "üîÅ Watermark updated ‚Üí 2026-01-17T01:56:37+0000\n",
      "‚û° activity_reply | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_reply\n",
      "üîÅ Watermark updated ‚Üí 2026-01-15T02:47:22+0000\n",
      "‚û° activity_sent | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_sent\n",
      "üîÅ Watermark updated ‚Üí 2026-01-09T20:57:57+0000\n",
      "‚û° activity_clicks | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí activity_clicks\n",
      "üîÅ Watermark updated ‚Üí 2025-05-27T18:38:42+0000\n",
      "‚û° created_leads | first_run=True\n",
      "üü¶ SNAPSHOT ‚Üí created_leads\n",
      "üîÅ Watermark updated ‚Üí 2026-01-15T02:51:25+0000\n",
      "‚úÖ Team 106422 COMPLETED\n",
      "\n",
      "üèÅ JOB FINISHED\n"
     ]
    }
   ],
   "source": [
    "#incremental code update\n",
    "\n",
    "#new code\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import boto3\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# GLOBALS\n",
    "# ============================================================================\n",
    "BASE = \"https://api.mailshake.com/2017-04-01\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "BUCKET = \"mailshake-analytics\"\n",
    "RAW_PREFIX = \"raw\"\n",
    "WATERMARK_PREFIX = \"metadata/watermark\"\n",
    "TEAMS_KEY = \"config/teams_test1.json\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "RUN_DATE = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ============================================================================\n",
    "# Team CONFIG\n",
    "# ============================================================================\n",
    "def load_teams() -> Dict[str, Dict[str, str]]:\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=TEAMS_KEY)\n",
    "    return json.loads(obj[\"Body\"].read().decode(\"utf-8\")).get(\"teams\", {})\n",
    "\n",
    "# ============================================================================\n",
    "# SAFE POST\n",
    "# ============================================================================\n",
    "def safe_post(url: str, payload: Dict[str, Any], auth: HTTPBasicAuth) -> requests.Response:\n",
    "    resp = requests.post(url, json=payload, headers=HEADERS, auth=auth, timeout=30)\n",
    "    if resp.status_code == 429:\n",
    "        print(\"üö´ API RATE LIMIT HIT ‚Äî STOPPING JOB\")\n",
    "        raise SystemExit(1)\n",
    "    resp.raise_for_status()\n",
    "    return resp\n",
    "\n",
    "# ============================================================================\n",
    "# WATERMARK HELPERS\n",
    "# ============================================================================\n",
    "def read_watermarks(team_id: str) -> dict:\n",
    "    key = f\"{WATERMARK_PREFIX}/watermark_{team_id}.json\"\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        return json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "    except s3.exceptions.NoSuchKey:\n",
    "        return {}\n",
    "\n",
    "def update_watermarks(team_id: str, new_data: dict):\n",
    "    key = f\"{WATERMARK_PREFIX}/watermark_{team_id}.json\"\n",
    "    current = read_watermarks(team_id)\n",
    "    current.update(new_data)\n",
    "    s3.put_object(Bucket=BUCKET, Key=key, Body=json.dumps(current, indent=2).encode(\"utf-8\"))\n",
    "\n",
    "def get_watermark(team_id: str, entity: str) -> str:\n",
    "    watermarks = read_watermarks(team_id)\n",
    "    return watermarks.get(entity, \"1970-01-01T00:00:00Z\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE PARQUET (SNAPSHOT OR INCREMENTAL)\n",
    "# ============================================================================\n",
    "# ============================================================================\n",
    "# SAVE PARQUET (SNAPSHOT OR INCREMENTAL) ‚Äî FULL SPARK SAFE WITH WATERMARK\n",
    "# ============================================================================\n",
    "def save_snapshot_or_incremental(\n",
    "    data: list, team_id: str, entity: str, ts_col: str, first_run: bool\n",
    "):\n",
    "    if not data:\n",
    "        print(f\"‚ö†Ô∏è No data for {entity}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert timestamp column if exists\n",
    "    if ts_col in df.columns:\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col], errors=\"coerce\", utc=True)\n",
    "        df = df.dropna(subset=[ts_col])\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"‚ö†Ô∏è No valid timestamps for {entity}\")\n",
    "            return None\n",
    "\n",
    "        # Spark-safe ISO format\n",
    "        df[ts_col] = df[ts_col].dt.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {ts_col} missing ‚Äî saving anyway\")\n",
    "\n",
    "    batch_ts = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "    # -------------------------\n",
    "    # FIRST RUN ‚Üí SNAPSHOT\n",
    "    # -------------------------\n",
    "    if first_run:\n",
    "        file = f\"/tmp/{team_id}_{entity}_snapshot.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/team_id={team_id}/entity={entity}/snapshot/{entity}.parquet\"\n",
    "        df.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"üü¶ SNAPSHOT ‚Üí {entity}\")\n",
    "        return df[ts_col].max() if ts_col in df.columns else None\n",
    "\n",
    "    # -------------------------\n",
    "    # FILTER BY SAVED WATERMARK\n",
    "    # -------------------------\n",
    "    current_wm = get_watermark(team_id, entity)\n",
    "    print(current_wm)\n",
    "    if ts_col in df.columns and current_wm:\n",
    "        current_wm_dt = pd.to_datetime(current_wm, utc=True)\n",
    "        df = df[pd.to_datetime(df[ts_col], utc=True) > current_wm_dt]\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No new records for {entity} after watermark {current_wm}\")\n",
    "        return None\n",
    "\n",
    "    # -------------------------\n",
    "    # CREATED_LEADS ‚Üí run_date partition\n",
    "    # -------------------------\n",
    "    if entity == \"created_leads\":\n",
    "        new_wm = df[ts_col].max() if ts_col in df.columns else batch_ts\n",
    "        wm_suffix = new_wm.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "        file = f\"/tmp/{team_id}_{entity}_{wm_suffix}.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/team_id={team_id}/entity={entity}/run_date={RUN_DATE}/{entity}_{wm_suffix}.parquet\"\n",
    "        df.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"üü¢ INCREMENTAL ‚Üí {entity} ({len(df)})\")\n",
    "        return new_wm\n",
    "\n",
    "    # -------------------------\n",
    "    # ACTIVITIES ‚Üí event_date partition\n",
    "    # -------------------------\n",
    "    if ts_col in df.columns:\n",
    "        df[\"event_date\"] = pd.to_datetime(df[ts_col], utc=True).dt.strftime(\"%Y-%m-%d\")\n",
    "        new_wm = df[ts_col].max()\n",
    "    else:\n",
    "        df[\"event_date\"] = RUN_DATE\n",
    "        new_wm = batch_ts\n",
    "\n",
    "    for d in df[\"event_date\"].unique():\n",
    "        part = df[df[\"event_date\"] == d].copy()\n",
    "        part.drop(columns=[\"event_date\"], inplace=True)\n",
    "        wm_suffix = new_wm.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "        file = f\"/tmp/{team_id}_{entity}_{d}_{wm_suffix}.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/team_id={team_id}/entity={entity}/event_date={d}/{entity}_{wm_suffix}.parquet\"\n",
    "        part.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"üü¢ INCREMENTAL ‚Üí {entity} ({len(part)})\")\n",
    "\n",
    "    return new_wm\n",
    "\n",
    "# ============================================================================\n",
    "# FETCH FUNCTIONS\n",
    "# ============================================================================\n",
    "def fetch_campaigns(team_id: str, auth: HTTPBasicAuth) -> List[Dict[str, Any]]:\n",
    "    resp = safe_post(f\"{BASE}/campaigns/list\", {\"teamID\": team_id}, auth)\n",
    "    return resp.json().get(\"results\", []) or []\n",
    "\n",
    "def fetch_activity(team_id: str, api_name: str, since_ts: str, auth: HTTPBasicAuth) -> List[Dict[str, Any]]:\n",
    "    resp = safe_post(f\"{BASE}/activity/{api_name}\", {\"teamID\": team_id, \"since_ts\": since_ts}, auth)\n",
    "    return resp.json().get(\"results\", []) or []\n",
    "\n",
    "# ============================================================================\n",
    "# RUN SINGLE team\n",
    "# ============================================================================\n",
    "def run_team(team: Dict[str, str]):\n",
    "    team_id, team_id, auth = team[\"team_id\"], team[\"team_id\"], HTTPBasicAuth(team[\"api_token\"], \"\")\n",
    "    print(f\"\\nüöÄ STARTING Team {team_id}\")\n",
    "\n",
    "    # -------- CAMPAIGNS (FULL LOAD) --------\n",
    "    campaigns = fetch_campaigns(team_id, auth)\n",
    "    if campaigns:\n",
    "        wm = save_snapshot_or_incremental(campaigns, team_id, \"campaign\", \"created\", first_run=True)\n",
    "        if wm:\n",
    "            update_watermarks(team_id, {\"campaign\": wm})\n",
    "\n",
    "    # -------- ACTIVITIES / CREATED_LEADS (INCREMENTAL) --------\n",
    "    activity_map = {\n",
    "        \"activity_open\": (\"opens\", \"actionDate\"),\n",
    "        \"activity_reply\": (\"replies\", \"actionDate\"),\n",
    "        \"activity_sent\": (\"sent\", \"actionDate\"),\n",
    "        \"activity_clicks\": (\"clicks\",\"actionDate\"),\n",
    "        \"created_leads\": (\"created-leads\", \"created\")\n",
    "    }\n",
    "\n",
    "    watermarks = read_watermarks(team_id)\n",
    "\n",
    "    for entity, (api, ts_col) in activity_map.items():\n",
    "        watermark = watermarks.get(entity, \"1970-01-01T00:00:00Z\")\n",
    "        first_run = entity not in watermarks\n",
    "        print(f\"‚û° {entity} | first_run={first_run}\")\n",
    "\n",
    "        data = fetch_activity(team_id, api, watermark, auth)\n",
    "        if not data:\n",
    "            print(f\"‚ö†Ô∏è No new records for {entity}\")\n",
    "            continue\n",
    "\n",
    "        new_wm = save_snapshot_or_incremental(data, team_id, entity, ts_col, first_run)\n",
    "\n",
    "        if new_wm:\n",
    "            old_wm = watermarks.get(entity)\n",
    "            if old_wm is None or new_wm > old_wm:\n",
    "                update_watermarks(team_id, {entity: new_wm})\n",
    "                watermarks[entity] = new_wm\n",
    "                print(f\"üîÅ Watermark updated ‚Üí {new_wm}\")\n",
    "\n",
    "    print(f\"‚úÖ Team {team_id} COMPLETED\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    teams = load_teams()\n",
    "    for team_id, team_cfg in teams.items():\n",
    "        try:\n",
    "            run_team({\n",
    "                \"team_id\": team_id,\n",
    "                \"team_id\": team_cfg[\"team_id\"],\n",
    "                \"api_token\": team_cfg[\"api_token\"]\n",
    "            })\n",
    "        except SystemExit:\n",
    "            print(\"üö´ API LIMIT HIT ‚Äî STOPPING ALL teamS\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå team {team_id} failed: {e}\")\n",
    "\n",
    "    print(\"\\nüèÅ JOB FINISHED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d688d-40b8-42c4-8076-db8ef5ea83d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
