{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ff4bfb-6012-4c21-9ad8-fa190135011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.4 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.20.3; python_version < \"3.10\"\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.3 MB 51 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 348 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: numpy, tzdata, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1285345f-ce9c-4e9f-8eb6-4161fcf849c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.37.38-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.38\n",
      "  Downloading botocore-1.37.38-py3-none-any.whl (13.5 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.5 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.12.0,>=0.11.0\n",
      "  Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84 kB 1.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.25.4; python_version < \"3.10\"\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 144 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.38.0,>=1.37.38->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.38->boto3) (1.17.0)\n",
      "Installing collected packages: jmespath, urllib3, botocore, s3transfer, boto3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed boto3-1.37.38 botocore-1.37.38 jmespath-1.0.1 s3transfer-0.11.5 urllib3-1.26.20\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea47a8d-3089-4987-80c3-c2153efb337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40.0 MB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from pyarrow) (1.24.4)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-17.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2015bb-f99c-4902-b765-91abf099f2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ STARTING CLIENT client_4\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=False\n",
      "2026-01-03T06:04:47+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (10)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (27)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (1)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T14:50:38+0000\n",
      "‚û° activity_reply | first_run=False\n",
      "2026-01-02T16:17:03+00:00\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (1)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (2)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T14:14:11+0000\n",
      "‚û° activity_sent | first_run=False\n",
      "2026-01-02T22:53:58.827000+00:00\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (11)\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (14)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T15:09:58+0000\n",
      "‚û° created_leads | first_run=False\n",
      "2026-01-02T16:32:30.997000+00:00\n",
      "üü¢ INCREMENTAL ‚Üí created_leads (2)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T14:24:12+0000\n",
      "‚úÖ CLIENT client_4 COMPLETED\n",
      "\n",
      "üöÄ STARTING CLIENT client_5\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=False\n",
      "2026-01-03T14:36:48+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (7)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (17)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (5)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (1)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T14:36:51+0000\n",
      "‚û° activity_reply | first_run=False\n",
      "2026-01-02T21:25:00+00:00\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (1)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (3)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (2)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (3)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T00:17:29+0000\n",
      "‚û° activity_sent | first_run=False\n",
      "2026-01-03T14:48:03+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (25)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T15:12:05+0000\n",
      "‚û° created_leads | first_run=False\n",
      "2025-12-29T15:14:45.994000+00:00\n",
      "‚ö†Ô∏è No new records for created_leads after watermark 2025-12-29T15:14:45.994000+00:00\n",
      "‚úÖ CLIENT client_5 COMPLETED\n",
      "\n",
      "üöÄ STARTING CLIENT client_6\n",
      "üü¶ SNAPSHOT ‚Üí campaign\n",
      "‚û° activity_open | first_run=False\n",
      "2026-01-03T00:13:40+0000\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (3)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (9)\n",
      "üü¢ INCREMENTAL ‚Üí activity_open (1)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T13:29:47+0000\n",
      "‚û° activity_reply | first_run=False\n",
      "2026-01-02T17:53:00+00:00\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (1)\n",
      "üü¢ INCREMENTAL ‚Üí activity_reply (3)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T13:29:48+0000\n",
      "‚û° activity_sent | first_run=False\n",
      "2026-01-02T21:02:57.466000+00:00\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (12)\n",
      "üü¢ INCREMENTAL ‚Üí activity_sent (13)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T15:12:03+0000\n",
      "‚û° created_leads | first_run=False\n",
      "2025-12-28T18:52:04.783000+00:00\n",
      "üü¢ INCREMENTAL ‚Üí created_leads (2)\n",
      "üîÅ Watermark updated ‚Üí 2026-01-06T13:40:16+0000\n",
      "‚úÖ CLIENT client_6 COMPLETED\n",
      "\n",
      "üèÅ JOB FINISHED\n"
     ]
    }
   ],
   "source": [
    "#incremental code update\n",
    "\n",
    "#new code\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "import boto3\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================================\n",
    "# GLOBALS\n",
    "# ============================================================================\n",
    "BASE = \"https://api.mailshake.com/2017-04-01\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "BUCKET = \"mailshake-analytics\"\n",
    "RAW_PREFIX = \"raw\"\n",
    "WATERMARK_PREFIX = \"metadata/watermark\"\n",
    "CLIENTS_KEY = \"config/clients_test.json\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "RUN_DATE = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ============================================================================\n",
    "# CLIENT CONFIG\n",
    "# ============================================================================\n",
    "def load_clients() -> Dict[str, Dict[str, str]]:\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=CLIENTS_KEY)\n",
    "    return json.loads(obj[\"Body\"].read().decode(\"utf-8\")).get(\"clients\", {})\n",
    "\n",
    "# ============================================================================\n",
    "# SAFE POST\n",
    "# ============================================================================\n",
    "def safe_post(url: str, payload: Dict[str, Any], auth: HTTPBasicAuth) -> requests.Response:\n",
    "    resp = requests.post(url, json=payload, headers=HEADERS, auth=auth, timeout=30)\n",
    "    if resp.status_code == 429:\n",
    "        print(\"üö´ API RATE LIMIT HIT ‚Äî STOPPING JOB\")\n",
    "        raise SystemExit(1)\n",
    "    resp.raise_for_status()\n",
    "    return resp\n",
    "\n",
    "# ============================================================================\n",
    "# WATERMARK HELPERS\n",
    "# ============================================================================\n",
    "def read_watermarks(client_id: str) -> dict:\n",
    "    key = f\"{WATERMARK_PREFIX}/watermark_{client_id}.json\"\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        return json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "    except s3.exceptions.NoSuchKey:\n",
    "        return {}\n",
    "\n",
    "def update_watermarks(client_id: str, new_data: dict):\n",
    "    key = f\"{WATERMARK_PREFIX}/watermark_{client_id}.json\"\n",
    "    current = read_watermarks(client_id)\n",
    "    current.update(new_data)\n",
    "    s3.put_object(Bucket=BUCKET, Key=key, Body=json.dumps(current, indent=2).encode(\"utf-8\"))\n",
    "\n",
    "def get_watermark(client_id: str, entity: str) -> str:\n",
    "    watermarks = read_watermarks(client_id)\n",
    "    return watermarks.get(entity, \"1970-01-01T00:00:00Z\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE PARQUET (SNAPSHOT OR INCREMENTAL)\n",
    "# ============================================================================\n",
    "# ============================================================================\n",
    "# SAVE PARQUET (SNAPSHOT OR INCREMENTAL) ‚Äî FULL SPARK SAFE WITH WATERMARK\n",
    "# ============================================================================\n",
    "def save_snapshot_or_incremental(\n",
    "    data: list, client_id: str, entity: str, ts_col: str, first_run: bool\n",
    "):\n",
    "    if not data:\n",
    "        print(f\"‚ö†Ô∏è No data for {entity}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert timestamp column if exists\n",
    "    if ts_col in df.columns:\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col], errors=\"coerce\", utc=True)\n",
    "        df = df.dropna(subset=[ts_col])\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"‚ö†Ô∏è No valid timestamps for {entity}\")\n",
    "            return None\n",
    "\n",
    "        # Spark-safe ISO format\n",
    "        df[ts_col] = df[ts_col].dt.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {ts_col} missing ‚Äî saving anyway\")\n",
    "\n",
    "    batch_ts = datetime.utcnow().strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "    # -------------------------\n",
    "    # FIRST RUN ‚Üí SNAPSHOT\n",
    "    # -------------------------\n",
    "    if first_run:\n",
    "        file = f\"/tmp/{client_id}_{entity}_snapshot.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/client_id={client_id}/entity={entity}/snapshot/{entity}.parquet\"\n",
    "        df.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"üü¶ SNAPSHOT ‚Üí {entity}\")\n",
    "        return df[ts_col].max() if ts_col in df.columns else None\n",
    "\n",
    "    # -------------------------\n",
    "    # FILTER BY SAVED WATERMARK\n",
    "    # -------------------------\n",
    "    current_wm = get_watermark(client_id, entity)\n",
    "    print(current_wm)\n",
    "    if ts_col in df.columns and current_wm:\n",
    "        current_wm_dt = pd.to_datetime(current_wm, utc=True)\n",
    "        df = df[pd.to_datetime(df[ts_col], utc=True) > current_wm_dt]\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No new records for {entity} after watermark {current_wm}\")\n",
    "        return None\n",
    "\n",
    "    # -------------------------\n",
    "    # CREATED_LEADS ‚Üí run_date partition\n",
    "    # -------------------------\n",
    "    if entity == \"created_leads\":\n",
    "        new_wm = df[ts_col].max() if ts_col in df.columns else batch_ts\n",
    "        wm_suffix = new_wm.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "        file = f\"/tmp/{client_id}_{entity}_{wm_suffix}.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/client_id={client_id}/entity={entity}/run_date={RUN_DATE}/{entity}_{wm_suffix}.parquet\"\n",
    "        df.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"üü¢ INCREMENTAL ‚Üí {entity} ({len(df)})\")\n",
    "        return new_wm\n",
    "\n",
    "    # -------------------------\n",
    "    # ACTIVITIES ‚Üí event_date partition\n",
    "    # -------------------------\n",
    "    if ts_col in df.columns:\n",
    "        df[\"event_date\"] = pd.to_datetime(df[ts_col], utc=True).dt.strftime(\"%Y-%m-%d\")\n",
    "        new_wm = df[ts_col].max()\n",
    "    else:\n",
    "        df[\"event_date\"] = RUN_DATE\n",
    "        new_wm = batch_ts\n",
    "\n",
    "    for d in df[\"event_date\"].unique():\n",
    "        part = df[df[\"event_date\"] == d].copy()\n",
    "        part.drop(columns=[\"event_date\"], inplace=True)\n",
    "        wm_suffix = new_wm.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "        file = f\"/tmp/{client_id}_{entity}_{d}_{wm_suffix}.parquet\"\n",
    "        key = f\"{RAW_PREFIX}/client_id={client_id}/entity={entity}/event_date={d}/{entity}_{wm_suffix}.parquet\"\n",
    "        part.to_parquet(file, index=False)\n",
    "        s3.upload_file(file, BUCKET, key)\n",
    "        print(f\"üü¢ INCREMENTAL ‚Üí {entity} ({len(part)})\")\n",
    "\n",
    "    return new_wm\n",
    "\n",
    "# ============================================================================\n",
    "# FETCH FUNCTIONS\n",
    "# ============================================================================\n",
    "def fetch_campaigns(team_id: str, auth: HTTPBasicAuth) -> List[Dict[str, Any]]:\n",
    "    resp = safe_post(f\"{BASE}/campaigns/list\", {\"teamID\": team_id}, auth)\n",
    "    return resp.json().get(\"results\", []) or []\n",
    "\n",
    "def fetch_activity(team_id: str, api_name: str, since_ts: str, auth: HTTPBasicAuth) -> List[Dict[str, Any]]:\n",
    "    resp = safe_post(f\"{BASE}/activity/{api_name}\", {\"teamID\": team_id, \"since_ts\": since_ts}, auth)\n",
    "    return resp.json().get(\"results\", []) or []\n",
    "\n",
    "# ============================================================================\n",
    "# RUN SINGLE CLIENT\n",
    "# ============================================================================\n",
    "def run_client(client: Dict[str, str]):\n",
    "    client_id, team_id, auth = client[\"client_id\"], client[\"team_id\"], HTTPBasicAuth(client[\"api_token\"], \"\")\n",
    "    print(f\"\\nüöÄ STARTING CLIENT {client_id}\")\n",
    "\n",
    "    # -------- CAMPAIGNS (FULL LOAD) --------\n",
    "    campaigns = fetch_campaigns(team_id, auth)\n",
    "    if campaigns:\n",
    "        wm = save_snapshot_or_incremental(campaigns, client_id, \"campaign\", \"created\", first_run=True)\n",
    "        if wm:\n",
    "            update_watermarks(client_id, {\"campaign\": wm})\n",
    "\n",
    "    # -------- ACTIVITIES / CREATED_LEADS (INCREMENTAL) --------\n",
    "    activity_map = {\n",
    "        \"activity_open\": (\"opens\", \"actionDate\"),\n",
    "        \"activity_reply\": (\"replies\", \"actionDate\"),\n",
    "        \"activity_sent\": (\"sent\", \"actionDate\"),\n",
    "        \"created_leads\": (\"created-leads\", \"created\")\n",
    "    }\n",
    "\n",
    "    watermarks = read_watermarks(client_id)\n",
    "\n",
    "    for entity, (api, ts_col) in activity_map.items():\n",
    "        watermark = watermarks.get(entity, \"1970-01-01T00:00:00Z\")\n",
    "        first_run = entity not in watermarks\n",
    "        print(f\"‚û° {entity} | first_run={first_run}\")\n",
    "\n",
    "        data = fetch_activity(team_id, api, watermark, auth)\n",
    "        if not data:\n",
    "            print(f\"‚ö†Ô∏è No new records for {entity}\")\n",
    "            continue\n",
    "\n",
    "        new_wm = save_snapshot_or_incremental(data, client_id, entity, ts_col, first_run)\n",
    "\n",
    "        if new_wm:\n",
    "            old_wm = watermarks.get(entity)\n",
    "            if old_wm is None or new_wm > old_wm:\n",
    "                update_watermarks(client_id, {entity: new_wm})\n",
    "                watermarks[entity] = new_wm\n",
    "                print(f\"üîÅ Watermark updated ‚Üí {new_wm}\")\n",
    "\n",
    "    print(f\"‚úÖ CLIENT {client_id} COMPLETED\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    clients = load_clients()\n",
    "    for client_id, client_cfg in clients.items():\n",
    "        try:\n",
    "            run_client({\n",
    "                \"client_id\": client_id,\n",
    "                \"team_id\": client_cfg[\"team_id\"],\n",
    "                \"api_token\": client_cfg[\"api_token\"]\n",
    "            })\n",
    "        except SystemExit:\n",
    "            print(\"üö´ API LIMIT HIT ‚Äî STOPPING ALL CLIENTS\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Client {client_id} failed: {e}\")\n",
    "\n",
    "    print(\"\\nüèÅ JOB FINISHED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d688d-40b8-42c4-8076-db8ef5ea83d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
